{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please install the required Python modules/SDKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! activate ai-azure-c1\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/opt/conda/envs/ai-azure-c1/lib/python3.8/site-packages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This demo uses the latest pillow package to show the rectangular bounding box around the face, so please upgrade the pillow package using the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pillow==8.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Useful Python Libraries or Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import requests\n",
    "import io\n",
    "import glob, os, sys, time, uuid\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType\n",
    "from msrest.authentication import CognitiveServicesCredentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Specific Azure Resources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVKASH_FACE_KEY = \"\"\n",
    "AVKASH_FACE_ENDPOINT = \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a client\n",
    "face_client = FaceClient(AVKASH_FACE_ENDPOINT, CognitiveServicesCredentials(AVKASH_FACE_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_client.api_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, upload several images of your own to this workspace and modify the code below as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: human-face*.jpg: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!ls human-face*.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "my_face_images = [file for file in glob.glob('*.jpg') if file.startswith(\"human-face\")]\n",
    "print(my_face_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in my_face_images:\n",
    "    with open(img, 'rb') as img_code:\n",
    "        img_view_ready = Image.open(img_code)\n",
    "        plt.figure()\n",
    "        plt.imshow(img_view_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Person Model Based on your face images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSON_GROUP_ID = str(uuid.uuid4())\n",
    "person_group_name = 'new_persoon_group_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code is taken from Azure face SDK \n",
    "## ---------------------------------------\n",
    "def build_person_group(client, person_group_id, pgp_name):\n",
    "    print('Create and build a person group...')\n",
    "    # Create empty Person Group. Person Group ID must be lower case, alphanumeric, and/or with '-', '_'.\n",
    "    print('Person group ID:', person_group_id)\n",
    "    client.person_group.create(person_group_id = person_group_id, name=person_group_id)\n",
    "\n",
    "    # Create a person group person.\n",
    "    my_face = client.person_group_person.create(person_group_id, pgp_name)\n",
    "    # Find all jpeg images of human in working directory.\n",
    "    my_face_images = [file for file in glob.glob('*.jpg') if file.startswith(\"human-face\")]\n",
    "    # Add images to a Person object\n",
    "    for image_p in my_face_images:\n",
    "        with open(image_p, 'rb') as w:\n",
    "            client.person_group_person.add_face_from_stream(person_group_id, my_face.person_id, w)\n",
    "\n",
    "    # Train the person group, after a Person object with many images were added to it.\n",
    "    client.person_group.train(person_group_id)\n",
    "\n",
    "    # Wait for training to finish.\n",
    "    while (True):\n",
    "        training_status = client.person_group.get_training_status(person_group_id)\n",
    "        print(\"Training status: {}.\".format(training_status.status))\n",
    "        if (training_status.status is TrainingStatusType.succeeded):\n",
    "            break\n",
    "        elif (training_status.status is TrainingStatusType.failed):\n",
    "            client.person_group.delete(person_group_id=PERSON_GROUP_ID)\n",
    "            sys.exit('Training the person group has failed.')\n",
    "        time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create and build a person group...\n",
      "Person group ID: e0b0407f-53a1-45f9-aad2-9c6dc1bc2712\n"
     ]
    },
    {
     "ename": "APIErrorException",
     "evalue": "(InvalidRequest) Invalid request has been sent.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIErrorException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sq/7rl_x4153zvftn0ldswvwj6r0000gn/T/ipykernel_24143/998056734.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbuild_person_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mface_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPERSON_GROUP_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperson_group_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/sq/7rl_x4153zvftn0ldswvwj6r0000gn/T/ipykernel_24143/765144056.py\u001b[0m in \u001b[0;36mbuild_person_group\u001b[0;34m(client, person_group_id, pgp_name)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Create empty Person Group. Person Group ID must be lower case, alphanumeric, and/or with '-', '_'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Person group ID:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperson_group_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperson_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperson_group_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperson_group_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mperson_group_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Create a person group person.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AI-Enginear-Azure/cd0461-building-computer-vision-solutions-with-azure-project-starter/azure_engineer/lib/python3.7/site-packages/azure/cognitiveservices/vision/face/operations/_person_group_operations.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, person_group_id, name, user_data, recognition_model, custom_headers, raw, **operation_config)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAPIErrorException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deserialize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAPIErrorException\u001b[0m: (InvalidRequest) Invalid request has been sent."
     ]
    }
   ],
   "source": [
    "build_person_group(face_client, PERSON_GROUP_ID, person_group_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making sure the person model has faces and they all belong to the same person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Detect all faces in query image list, then add their face IDs to a new list.\n",
    "'''\n",
    "def detect_faces(client, query_images_list):\n",
    "    print('Detecting faces in query images list...')\n",
    "\n",
    "    face_ids = {} # Keep track of the image ID and the related image in a dictionary\n",
    "    for image_name in query_images_list:\n",
    "        image = open(image_name, 'rb') # BufferedReader\n",
    "        print(\"Opening image: \", image.name)\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Detect the faces in the query images list one at a time, returns list[DetectedFace]\n",
    "        faces = client.face.detect_with_stream(image)  \n",
    "\n",
    "        # Add all detected face IDs to a list\n",
    "        for face in faces:\n",
    "            print('Face ID', face.face_id, 'found in image', os.path.splitext(image.name)[0]+'.jpg')\n",
    "            # Add the ID to a dictionary with image name as a key.\n",
    "            # This assumes there is only one face per image (since you can't have duplicate keys)\n",
    "            face_ids[image.name] = face.face_id\n",
    "\n",
    "    return face_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's view the face-specific thumbnails "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = detect_faces(face_client, my_face_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that 2 random images from the list belong to the same person\n",
    "- ### Note: Modify your image file name if you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification example for faces of the same person.\n",
    "verify_result = face_client.face.verify_face_to_face(ids['human-face1.jpg'], ids['human-face2.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if verify_result.is_identical:\n",
    "    print(\"Faces are of the same (Positive) person, similarity confidence: {}.\".format(verify_result.confidence))\n",
    "else:\n",
    "    print(\"Faces are of different (Negative) persons, similarity confidence: {}.\".format(verify_result.confidence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match face from ID card with face from Video Analyzer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_in_cell(face_url):\n",
    "    response = requests.get(face_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your own image URL\n",
    "dl_source_url = 'https://raw.githubusercontent.com/udacity/cd0461-building-computer-vision-solutions-with-azure-exercises/main/resources/ca-dl-sample.png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_in_cell(dl_source_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -------\n",
    "## Reading file locally\n",
    "## -------\n",
    "# If I had image file locally I would have used the following method\n",
    "# dl_image = open('/your-local-file-system/udacity/cal-dl.png', 'rb')\n",
    "# dl_faces = face_client.face.detect_with_stream(dl_image)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_faces = face_client.face.detect_with_url(dl_source_url) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Face ID and then save it into the list of already saved Face IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in dl_faces:\n",
    "    print('Face ID', face.face_id, 'found in image', dl_source_url)\n",
    "    # Add the ID to a dictionary with image name as a key.\n",
    "    # This assumes there is only one face per image (since you can't have duplicate keys)\n",
    "    ids['ca-dl-sample.png'] = face.face_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, you have (n + 1) Face IDs in your Face ID list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform face verification between the 1 Face ID and the n Face IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification example for faces of the same person.\n",
    "dl_verify_result = face_client.face.verify_face_to_face(ids['human-face4.jpg'], ids['ca-dl-sample.png'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dl_verify_result.is_identical:\n",
    "    print(\"Faces are of the same (Positive) person, similarity confidence: {}.\".format(dl_verify_result.confidence))\n",
    "else:\n",
    "    print(\"Faces are of different (Negative) persons, similarity confidence: {}.\".format(dl_verify_result.confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids['ca-dl-sample.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_faces[0].face_rectangle.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAKEN FROM THE Azure SDK Sample\n",
    "# Convert width height to a point in a rectangle\n",
    "def getRectangle(faceDictionary):\n",
    "    rect = faceDictionary.face_rectangle\n",
    "    left = rect.left\n",
    "    top = rect.top\n",
    "    right = left + rect.width\n",
    "    bottom = top + rect.height\n",
    "    \n",
    "    return ((left, top), (right, bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawFaceRectangles(source_file, detected_face_object) :\n",
    "    # Download the image from the url\n",
    "    response = requests.get(source_file)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    # Draw a red box around every detected faces\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for face in detected_face_object:\n",
    "        draw.rectangle(getRectangle(face), outline='red', width = 10)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawFaceRectangles(dl_source_url, dl_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match Face ID from the face image URL with Person Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of Face ID\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the face ID of ca-dl-sample.png from the output of the cell above\n",
    "get_the_face_id_from_the_driving_license = 'ENTER FACE ID HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_gp_results = face_client.face.identify([get_the_face_id_from_the_driving_license], PERSON_GROUP_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in person_gp_results:\n",
    "    for candidate in result.candidates:\n",
    "        print(\"The Identity match confidence is {}\".format(candidate.confidence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
